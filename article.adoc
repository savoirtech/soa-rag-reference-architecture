== SOA RAG Reference Architecture

In this post we're going to explore a SOA RAG reference architecture.

image::./assets/images/HighLevelDesign.png[alt=HighLevelDesign,width=480,height=640,align="center"]

We'll start with high level design theory, then discuss an implementation.

image::./assets/images/NoBanner.png[alt=NoBanner,width=480,height=640,align="center"]

== High Level

One key to efficient Retrieval Augmented Generation is to pre-process segment data and query embeddings before a user required to use them.

To achieve this an architect may design a data pipeline that contains several stages.

=== Data Source

Data sources from our point of view are anything that produces data that our system consumes.

In our demo architecture we use DataFaker to produce inputs to our pipeline.

=== Data Landing Zone

When data is created and transmitted to our system, the collection of endpoints, brokers, and other services which collect primary data live here.

Examples:
Apache ActiveMQ, Apache Kafka

In our demo architecture we use Apache ActiveMQ as a JMS data sink.

=== ETL

Extract, Transform, Load is a design paradigm.

Incoming data is first extracted, then transformed into something we can process, the data may be enriched, then sent (loaded) for further processing or storage. In modern implementations business rules for cleaning/filtering data may be augmented with Machine Learning to improve data quality & apply metadata for improved reuse.

Examples:
Apache Camel, Apache Flink

In our demo architecture we use Apache Camel to implement an ETL pattern.

=== Vector Database

In generative AI settings a Vector Database acts as the memory for running agents.

Embeddings are efficiently indexed in a way to increase performance, accuracy, and relevance of data & query processed by the LLM.

Examples:
Chroma, Pinecone

In our demo architecture we use Chroma.

=== Agent System

The Agent System is where our interaction with our application, the Vector Datastore & the LLM occur.

We use Apache Karaf with a Backend-For-Frontend design to provide a web interface, and integration to LocalAI via LangChain4j.

== The Result

Once this pipeline is created, an agent may use the pre-populated embedded store for the LLM.


== Demo

Now that we've covered the high level design, lets build our demo implementation and deploy it. We've taken care to curate several of the components as Dockers. Leaving the initial data generation as a small Java tool we can execute from the command line, and our Agent system - which we'd like to dive deep into.

image::./assets/images/Deployment.png[alt=Deployment,width=480,height=640,align="center"]

Build our demo project:
[,bash,num]
----
cd agentSystem
mvn clean install
----

To setup ETL as a Dockerized Container:
[,bash,num]
----
cd ETLDocker/target
docker build -t etl .
----

Start supporting services:
[,bash,run]
----
cd docker
docker compose up
----

You may want to grab a cup of coffee while docker handles downloads, and service initializations.

When the Message Broker is running, you may populate the reservations queue using the provided dataSource script.

Script build and run instructions:
[,bash,num]
----
cd dataSource
mvn clean install
java -cp target/dataSource-1.0.0-SNAPSHOT.jar com.savoir.soa.rag.ref.arch.data.faker.Publisher
----

Setup Apache Karaf:

Install feature:
feature:repo-add mvn:com.savoir.soa.rag.ref.arch/AppFeature/1.0.0-SNAPSHOT/xml/features
feature:install agent
feature:install war
install -s webbundle:mvn:com.savoir.soa.rag.ref.arch/AppWar/${project.version}/war?Web-ContextPath=chat


Sample message body sent to reservations queue.
[,json,num]
----
{
  "firstName": "Claud",
  "lastName": "Sporer",
  "streetName": "Zemlak Tunnel",
  "streetAddress": "9843 Botsford Inlet",
  "zipcode": "18282",
  "email": "some.email@fake.email",
  "cell": "(555) 555-5555",
  "roomType": "balcony",
  "excursions": [
    {
      "1": "Beach",
      "2": "JetSki",
      "3": "Beach"
    }
  ],
  "mealOptions": [
    {
      "1": "Italian",
      "2": "Italian",
      "3": "WineTasting"
    }
  ]
}
----

Testing endpoints:
[,bash,num]
----
curl --location --request POST 'http://127.0.0.1:8181/cxf/ai/ask' \
--header 'Content-Type: text/plain' --header 'Accept: text/plain' -d 'test'
----

== Conclusion

== About the Authors

link:https://github.com/savoirtech/blogs/blob/main/authors/JamieGoodyear.md[Jamie Goodyear]

== Reaching Out

Please do not hesitate to reach out with questions and comments, here on the Blog, or through the Savoir Technologies website at https://www.savoirtech.com.

== With Thanks

Thank you to the JavaFaker, Apache ActiveMQ, Apache Camel, Apache Karaf, Apache CXF, LangChain4j, and LocalAI communities.

(c) 2024 Savoir Technologies
